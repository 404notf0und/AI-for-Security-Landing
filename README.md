# AI-for-Security-Landing-Guide
面向安全、数据、算法人员梳理的安全智能化落地指南

## 版本
  - 当前更新版本：2021-08-10 版本地址：[commit](https://github.com/404notf0und/AI-for-Security-Landing-Guide)
  - 如果您发现任何更新、问题或改进，请随时 fork 和 PR
  - Please feel free to fork and PR if you find any updates, issues or improvement.

## 目录
- [版本](#版本)
- [目录](#目录)
- [介绍](#介绍)
- [指导原则](#指导原则)
  - [检查数据标签纯净度](#检查数据标签纯净度)
  - [黑样本分布多样性](#黑样本分布多样性)
  - [避免黑样本浓度过低](#避免黑样本浓度过低)
  - [排查脏数据](#排查脏数据)
  - [特征工程选型](#特征工程选型)
  - [机器学习算法选型](#机器学习算法选型)
  - [机器学习算法调参](#机器学习算法调参)

## 介绍
该指南最初由 [404notfound@柳星] 编写，分享机器学习落地安全的经验，趟过的路，哪条路是通畅的，哪条路是需要避免的，目的是使一些同路人能快速Landing，同时也欢迎同路人加入一起编写。
[404notfound@柳星]: https://github.com/404notf0und

## 指导原则
### 检查数据标签纯净度
garbage in, garbage out。

训练阶段，检查黑白样本标签纯净度。尽可能100%纯净。如果，黑中有白，预测阶段会误报，白中有黑，预测阶段会漏报。

### 黑样本分布多样性
训练阶段，检查黑样本标签分布多样性。原始数据来源和风险标签类型尽可能覆盖全面，因为会影响到预测阶段模型的泛化性。

### 避免黑样本浓度过低
训练阶段，检查黑白样本标签分布均衡性。建议黑白样本比例最低控制在1:100～1:1000。可以通过白样本的下采样抽样和黑样本的上采样控制浓度。

### 检查脏数据
脏数据，可能会导致后续数据和算法处理有效率和性能问题。比如sql长耗时、算法长耗时，训练准、预测不准等问题。因此，当出现预期外的问题时，排查脏数据。

- 如果是处理效率问题，尝试数据截断
- 如果是算法性能问题，遵循第一条守则`检查数据标签`

### 特征工程选型
- 统计特征。考虑时间+空间维度，比如过去90天内xx的统计特征，当天xx的统计特征。
- 如果数据体现出行为序列方面的规律，使用NLP处理特征化。

### 机器学习算法选型
1. 在显性黑样本极少时，行为手法未知，风险类型不明，优先采用无监督算法发现事件，总结规律，写成规则。反之，优先采用有监督算法
2. 聚类算法优先采用dbscan（参数敏感型），异常检测优先采用iforest，有监督算法优先采用lgb
3. dbscan落地安全的优劣势
	- 优势：不需要输入类别数k；可以发现任意形状的聚类簇
	- 劣势：聚类收敛时间可能较长；调参复杂，需要联合调参

### 机器学习算法调参
- dbscan有2个核心参数，建议联合调参。
	1. 𝜖-邻域的距离阈值eps
	2. 𝜖-邻域的样本数阈值min_samples
